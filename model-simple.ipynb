{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# External\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Internal\n",
    "from model import ConvNet\n",
    "from dataset import HeightReconstructionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms images to a PyTorch Tensor\n",
    "tensor_transform = transforms.ToTensor()\n",
    "\n",
    "# create dataset\n",
    "train_dataset = HeightReconstructionDataset('./dataset_csv/161_train_dataset.csv', './grayscale_tensors', './quadratic_±100um', transform = tensor_transform)\n",
    "dev_dataset = HeightReconstructionDataset('./dataset_csv/161_dev_dataset.csv', './grayscale_tensors', './quadratic_±100um', transform = tensor_transform)\n",
    "test_dataset = HeightReconstructionDataset('./dataset_csv/161_test_dataset.csv', './grayscale_tensors', './quadratic_±100um', transform = tensor_transform)\n",
    "test_dataset.img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader is used to load the dataset for training\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = 8, shuffle = True)\n",
    "dev_loader = torch.utils.data.DataLoader(dataset = dev_dataset, batch_size = 1, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "  \n",
    "# Validation using MSE Loss function\n",
    "loss_function = torch.nn.MSELoss()\n",
    "  \n",
    "# Using an Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-2,\n",
    "                             weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "outputs = []\n",
    "train_losses = []\n",
    "dev_losses = []\n",
    "for epoch in range(epochs):\n",
    "    # train loop\n",
    "    for (input_tensor, heightmap) in train_loader:\n",
    "        # pass data to cuda\n",
    "        input_tensor, heightmap = input_tensor.to(device), heightmap.to(device)\n",
    "\n",
    "        # Output of Network\n",
    "        reconstructed = model(input_tensor)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_function(reconstructed, heightmap)\n",
    "\n",
    "        # The gradients are set to zero,\n",
    "        # the the gradient is computed and stored.\n",
    "        # .step() performs parameter update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Storing the losses in a list for plotting\n",
    "        train_loss = loss.cpu().detach().item()\n",
    "        train_losses += [train_loss]\n",
    "\n",
    "        print(train_loss)\n",
    "        \n",
    "    outputs += [(epochs, heightmap, reconstructed)]\n",
    "    \n",
    "    # validation loop\n",
    "    for (input_tensor, heightmap) in dev_loader:\n",
    "        # pass data to cuda\n",
    "        input_tensor, heightmap = input_tensor.to(device), heightmap.to(device)\n",
    "\n",
    "        # Output of Network\n",
    "        reconstructed = model(input_tensor)\n",
    "        \n",
    "        # Calculate loss\n",
    "        dev_loss = loss_function(reconstructed, heightmap).cpu().detach().item()\n",
    "        \n",
    "        dev_losses += [dev_loss]\n",
    "        \n",
    "    print(f\"<-------------------------- Epoch {epoch} -------------------------->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = []\n",
    "actual = []\n",
    "\n",
    "for (input_tensor, heightmap) in test_loader:\n",
    "    reconstructed = model(input_tensor.to(device))\n",
    "    reconstructed += [reconstructed.cpu().detach().numpy()[0, 0]]\n",
    "    \n",
    "    actual += [heightmap.cpu().detach().numpy()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "rows = len(reconstructed) + 1  # for legibility\n",
    "cols = 2\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, rows*6))\n",
    "fig.set_dpi(200)\n",
    "\n",
    "for i, ax_row in enumerate(axes):\n",
    "    # add train / dev loss curves\n",
    "    if i == rows - 1:\n",
    "        ax_row[0].set_xlabel('Iterations')\n",
    "        ax_row[0].set_ylabel('Loss')\n",
    "        ax_row[0].plot(train_losses);\n",
    "        ax_row[0].set_title('Training Loss')\n",
    "        ax_row[1].set_xlabel('Measurements')\n",
    "        ax_row[1].set_ylabel('Loss')\n",
    "        ax_row[1].plot(dev_losses);\n",
    "        ax_row[1].set_title('Validation Loss')\n",
    "        \n",
    "    else:\n",
    "        ax_row[0].imshow(actual[i])\n",
    "        ax_row[0].set_axis_off()\n",
    "        ax_row[0].set_title(f\"Ground Truth\\nmin: {np.nanmin(actual[i])}\\nmed: {np.nanmedian(actual[i])}\\nmax: {np.nanmax(actual[i])}\")\n",
    "        ax_row[1].imshow(reconstructed[i])\n",
    "        ax_row[1].set_axis_off()\n",
    "        ax_row[1].set_title(f\"Reconstructed\\nmin: {np.nanmin(reconstructed[i])}\\nmed: {np.nanmedian(reconstructed[i])}\\nmax: {np.nanmax(reconstructed[i])}\")\n",
    "    \n",
    "plt.savefig('./outputs/Model_7_±100um_Overview.png', dpi=200, facecolor='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
